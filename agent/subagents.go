package agent

import (
	"context"
	"fmt"
	"strings"

	"github.com/smallnest/goskills/tool"

	markdown "github.com/MichaelMure/go-term-markdown"
	gomarkdown "github.com/gomarkdown/markdown"
	"github.com/gomarkdown/markdown/html"
	"github.com/gomarkdown/markdown/parser"
	openai "github.com/sashabaranov/go-openai"
)

// SearchSubagent performs web searches.
type SearchSubagent struct {
	client             *openai.Client
	model              string
	verbose            bool
	interactionHandler InteractionHandler
}

// NewSearchSubagent creates a new SearchSubagent.
func NewSearchSubagent(client *openai.Client, model string, verbose bool, interactionHandler InteractionHandler) *SearchSubagent {
	return &SearchSubagent{
		client:             client,
		model:              model,
		verbose:            verbose,
		interactionHandler: interactionHandler,
	}
}

// Type returns the task type this subagent handles.
func (s *SearchSubagent) Type() TaskType {
	return TaskTypeSearch
}

// Execute performs a web search based on the task.
func (s *SearchSubagent) Execute(ctx context.Context, task Task) (Result, error) {
	if s.verbose {
		fmt.Println("ğŸŒ ç½‘ç»œæœç´¢ Subagent")
	}
	if s.interactionHandler != nil {
		s.interactionHandler.Log(fmt.Sprintf("> ç½‘ç»œæœç´¢ Subagent: %s", task.Description))
	}

	// Extract query from parameters
	query, ok := task.Parameters["query"].(string)
	if !ok {
		query = task.Description
	}

	if s.verbose {
		fmt.Printf("  æŸ¥è¯¢: %q\n", query)
	}
	if s.interactionHandler != nil {
		s.interactionHandler.Log(fmt.Sprintf("  æŸ¥è¯¢: %q", query))
	}

	// Perform Tavily search
	searchResult, err := tool.TavilySearch(query)
	if err != nil {
		// Fallback to DuckDuckGo if Tavily fails (e.g. missing key)
		if s.verbose {
			fmt.Printf("  âš ï¸ Tavily æœç´¢å¤±è´¥: %vã€‚å›é€€åˆ° DuckDuckGoã€‚\n", err)
		}
		if s.interactionHandler != nil {
			s.interactionHandler.Log(fmt.Sprintf("  âš ï¸ Tavily æœç´¢å¤±è´¥: %vã€‚å›é€€åˆ° DuckDuckGoã€‚", err))
		}
		searchResult, err = tool.DuckDuckGoSearch(query)
		if err != nil {
			return Result{
				TaskType: TaskTypeSearch,
				Success:  false,
				Error:    err.Error(),
			}, err
		}
	}

	// Reflection Loop
	maxIterations := 3
	accumulatedResults := searchResult

	for i := 0; i < maxIterations; i++ {
		// Prepare prompt for reflection
		reflectionPrompt := fmt.Sprintf(`ç”¨æˆ·æŸ¥è¯¢: %s
å½“å‰æœç´¢ç»“æœ:
%s

ä¿¡æ¯æ˜¯å¦è¶³ä»¥å›ç­”ç”¨æˆ·çš„æŸ¥è¯¢ï¼Ÿ
å¦‚æœæ˜¯ï¼Œè¯·ä»…å›å¤ "SUFFICIENT"ã€‚
å¦‚æœå¦ï¼Œè¯·å›å¤ä¸€ä¸ªæ–°çš„ã€æ›´ç²¾ç»†çš„æœç´¢æŸ¥è¯¢ä»¥æŸ¥æ‰¾ç¼ºå¤±çš„ä¿¡æ¯ã€‚ä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡æœ¬ã€‚`, query, accumulatedResults)

		// Truncate if too long to avoid context limit issues
		if len(reflectionPrompt) > 80000 {
			reflectionPrompt = reflectionPrompt[:80000] + "\n...(truncated)"
		}

		resp, err := s.client.CreateChatCompletion(ctx, openai.ChatCompletionRequest{
			Model: s.model,
			Messages: []openai.ChatCompletionMessage{
				{
					Role:    openai.ChatMessageRoleSystem,
					Content: "ä½ æ˜¯ä¸€ä¸ªæœç´¢ä¼˜åŒ–åŠ©æ‰‹ã€‚ä½ è¯„ä¼°æœç´¢ç»“æœå¹¶å†³å®šæ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯ã€‚",
				},
				{
					Role:    openai.ChatMessageRoleUser,
					Content: reflectionPrompt,
				},
			},
			Temperature: 0.1, // Low temp for decision making
		})

		if err != nil {
			if s.verbose {
				fmt.Printf("  âš ï¸ åæ€å¤±è´¥: %v\n", err)
			}
			if s.interactionHandler != nil {
				s.interactionHandler.Log(fmt.Sprintf("  âš ï¸ åæ€å¤±è´¥: %v", err))
			}
			break // Stop reflection if LLM fails
		}

		decision := strings.TrimSpace(resp.Choices[0].Message.Content)

		// Check if sufficient (case-insensitive check for robustness)
		if strings.Contains(strings.ToUpper(decision), "SUFFICIENT") {
			if s.verbose {
				fmt.Println("  âœ“ LLM è®¤ä¸ºä¿¡æ¯å·²å……è¶³ã€‚")
			}
			if s.interactionHandler != nil {
				s.interactionHandler.Log("  âœ“ LLM è®¤ä¸ºä¿¡æ¯å·²å……è¶³ã€‚")
			}
			break
		}

		// It's a new query
		newQuery := decision
		// Clean up quotes if present
		newQuery = strings.Trim(newQuery, "\"'")

		if s.verbose {
			fmt.Printf("  ğŸ”„ LLM è¯·æ±‚æ›´å¤šä¿¡æ¯ã€‚æ–°æŸ¥è¯¢: %q\n", newQuery)
		}
		if s.interactionHandler != nil {
			s.interactionHandler.Log(fmt.Sprintf("  ğŸ”„ LLM è¯·æ±‚æ›´å¤šä¿¡æ¯ã€‚æ–°æŸ¥è¯¢: %q", newQuery))
		}
		if s.interactionHandler != nil {
			s.interactionHandler.Log(fmt.Sprintf("ğŸ”„ è¡¥å……æœç´¢: %s", newQuery))
		}

		// Execute new search
		newResults, err := tool.TavilySearch(newQuery)
		if err != nil {
			// Try DDG fallback
			newResults, err = tool.DuckDuckGoSearch(newQuery)
		}

		if err == nil {
			accumulatedResults += "\n\n--- Additional Search Results ---\n" + newResults
		}
	}

	// Also try Wikipedia if results are sparse (optional, keeping existing logic)
	wikiResult, wikiErr := tool.WikipediaSearch(query)
	if wikiErr == nil && wikiResult != "" {
		accumulatedResults = fmt.Sprintf("ç½‘ç»œæœç´¢ç»“æœ:\n%s\n\nç»´åŸºç™¾ç§‘ç»“æœ:\n%s", accumulatedResults, wikiResult)
	}

	// Parse and log simplified results
	var resultLog strings.Builder
	resultLog.WriteString("å·²æ£€ç´¢ä¿¡æ¯:\n")

	// Simple parsing of the text format returned by TavilySearch
	// Format: Title: ...\nURL: ...\nContent: ...\n\n
	entries := strings.Split(accumulatedResults, "\n\n")
	for _, entry := range entries {
		if strings.TrimSpace(entry) == "" {
			continue
		}
		lines := strings.Split(entry, "\n")
		var title, url string
		for _, line := range lines {
			if strings.HasPrefix(line, "Title: ") {
				title = strings.TrimPrefix(line, "Title: ")
			} else if strings.HasPrefix(line, "URL: ") {
				url = strings.TrimPrefix(line, "URL: ")
			}
		}
		if title != "" && url != "" {
			resultLog.WriteString(fmt.Sprintf("- [%s](%s)\n", title, url))
		}
	}

	logContent := resultLog.String()
	if len([]rune(logContent)) > 200 {
		logContent = string([]rune(logContent)[:200]) + "..."
	}

	if s.verbose {
		fmt.Printf("\n  âœ“ %s\n", logContent)
	}
	if s.interactionHandler != nil {
		s.interactionHandler.Log(fmt.Sprintf("âœ“ %s", logContent))
	}

	return Result{
		TaskType: TaskTypeSearch,
		Success:  true,
		Output:   accumulatedResults,
		Metadata: map[string]interface{}{
			"query": query,
		},
	}, nil
}

// AnalysisSubagent analyzes and synthesizes information.
type AnalysisSubagent struct {
	client             *openai.Client
	model              string
	verbose            bool
	interactionHandler InteractionHandler
}

// NewAnalysisSubagent creates a new AnalysisSubagent.
func NewAnalysisSubagent(client *openai.Client, model string, verbose bool, interactionHandler InteractionHandler) *AnalysisSubagent {
	return &AnalysisSubagent{
		client:             client,
		model:              model,
		verbose:            verbose,
		interactionHandler: interactionHandler,
	}
}

// Type returns the task type this subagent handles.
func (a *AnalysisSubagent) Type() TaskType {
	return TaskTypeAnalyze
}

// Execute analyzes information using the LLM.
func (a *AnalysisSubagent) Execute(ctx context.Context, task Task) (Result, error) {
	if a.verbose {
		fmt.Println("ğŸ”¬ åˆ†æ Subagent")
	}
	if a.interactionHandler != nil {
		a.interactionHandler.Log(fmt.Sprintf("> åˆ†æ Subagent: %s", task.Description))
	}

	// Get context from parameters if available
	contextData, hasContext := task.Parameters["context"].([]string)

	var prompt string
	if hasContext && len(contextData) > 0 {
		prompt = fmt.Sprintf("åˆ†æä»¥ä¸‹ä¿¡æ¯å¹¶ %s:\n\n%s", task.Description, strings.Join(contextData, "\n\n"))
	} else {
		prompt = task.Description
	}

	// Check for global context
	globalContext, _ := task.Parameters["global_context"].(string)
	systemPrompt := "ä½ æ˜¯ä¸€ä¸ªåˆ†æåŠ©æ‰‹ï¼Œè´Ÿè´£ç»¼åˆå’Œåˆ†æä¿¡æ¯ã€‚è¯·æä¾›æ¸…æ™°ã€ç»“æ„åŒ–çš„åˆ†æã€‚\n" +
		"å¦‚æœæä¾›çš„ä¿¡æ¯ä¸è¶³ä»¥å®Œæˆåˆ†æï¼Œä½ å¯ä»¥è¯·æ±‚æ›´å¤šä¿¡æ¯ã€‚\n" +
		"å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œè¯·ä»…å›å¤ 'MISSING_INFO: <å…·ä½“çš„æœç´¢æŸ¥è¯¢>'ã€‚\n" +
		"ä¾‹å¦‚: 'MISSING_INFO: 2024å¹´Q3ç‰¹æ–¯æ‹‰è´¢æŠ¥æ•°æ®'"

	if globalContext != "" {
		systemPrompt += "\n\næ¥è‡ªç”¨æˆ·çš„é‡è¦ä¸Šä¸‹æ–‡/æŒ‡ä»¤ï¼š\n" + globalContext
	}

	messages := []openai.ChatCompletionMessage{
		{
			Role:    openai.ChatMessageRoleSystem,
			Content: systemPrompt,
		},
		{
			Role:    openai.ChatMessageRoleUser,
			Content: prompt,
		},
	}

	req := openai.ChatCompletionRequest{
		Model:       a.model,
		Messages:    messages,
		Temperature: 0.3,
	}

	resp, err := a.client.CreateChatCompletion(ctx, req)
	if err != nil {
		return Result{
			TaskType: TaskTypeAnalyze,
			Success:  false,
			Error:    err.Error(),
		}, err
	}

	analysis := resp.Choices[0].Message.Content

	// Check for MISSING_INFO signal
	if strings.HasPrefix(strings.TrimSpace(analysis), "MISSING_INFO:") {
		newQuery := strings.TrimSpace(strings.TrimPrefix(strings.TrimSpace(analysis), "MISSING_INFO:"))

		if a.verbose {
			fmt.Printf("  ğŸ”„ åˆ†æå‘ç°ä¿¡æ¯ç¼ºå¤±ï¼Œè¯·æ±‚æ–°æœç´¢: %q\n", newQuery)
		}
		if a.interactionHandler != nil {
			a.interactionHandler.Log(fmt.Sprintf("ğŸ”„ åˆ†æå‘ç°ä¿¡æ¯ç¼ºå¤±ï¼Œè¯·æ±‚æ–°æœç´¢: %q", newQuery))
		}

		// Create new tasks
		newTasks := []Task{
			{
				Type:        TaskTypeSearch,
				Description: newQuery,
				Parameters: map[string]interface{}{
					"query": newQuery,
				},
			},
			// Re-queue the current analysis task to run after the search
			task,
		}

		return Result{
			TaskType: TaskTypeAnalyze,
			Success:  true, // Step succeeded in identifying need
			Output:   fmt.Sprintf("æ­£åœ¨è¯·æ±‚æ›´å¤šä¿¡æ¯: %s", newQuery),
			NewTasks: newTasks,
		}, nil
	}

	if a.verbose {
		fmt.Printf("  âœ“ ä¿¡æ¯è¿™å·²è¶³å¤Ÿï¼Œåˆ†æå®Œæˆ (%d å­—èŠ‚)\n", len(analysis))
	}
	if a.interactionHandler != nil {
		a.interactionHandler.Log(fmt.Sprintf("âœ“ ä¿¡æ¯è¿™å·²è¶³å¤Ÿï¼Œåˆ†æå®Œæˆ (%d å­—èŠ‚)", len(analysis)))
	}

	return Result{
		TaskType: TaskTypeAnalyze,
		Success:  true,
		Output:   analysis,
	}, nil
}

// ReportSubagent generates formatted reports.
type ReportSubagent struct {
	client             *openai.Client
	model              string
	verbose            bool
	interactionHandler InteractionHandler
}

// NewReportSubagent creates a new ReportSubagent.
func NewReportSubagent(client *openai.Client, model string, verbose bool, interactionHandler InteractionHandler) *ReportSubagent {
	return &ReportSubagent{
		client:             client,
		model:              model,
		verbose:            verbose,
		interactionHandler: interactionHandler,
	}
}

// Type returns the task type this subagent handles.
func (r *ReportSubagent) Type() TaskType {
	return TaskTypeReport
}

// Execute generates a formatted report.
func (r *ReportSubagent) Execute(ctx context.Context, task Task) (Result, error) {
	if r.verbose {
		fmt.Println("ğŸ“ æŠ¥å‘Š Subagent")
	}
	if r.interactionHandler != nil {
		r.interactionHandler.Log(fmt.Sprintf("> æŠ¥å‘Š Subagent: %s", task.Description))
	}

	// Get context from parameters if available
	contextData, hasContext := task.Parameters["context"].([]string)

	var prompt string
	if hasContext && len(contextData) > 0 {
		prompt = fmt.Sprintf("åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œ%s:\n\n%s", task.Description, strings.Join(contextData, "\n\n"))
	} else {
		prompt = task.Description
	}

	// Check for global context
	globalContext, _ := task.Parameters["global_context"].(string)
	systemPrompt := "ä½ æ˜¯ä¸€ä¸ªæŠ¥å‘Šå†™ä½œåŠ©æ‰‹ï¼Œè´Ÿè´£åˆ›å»ºæ ¼å¼è‰¯å¥½ã€æ¸…æ™°ä¸”å…¨é¢çš„ Markdown æ ¼å¼æŠ¥å‘Šã€‚ä½¿ç”¨é€‚å½“çš„æ ‡é¢˜ã€åˆ—è¡¨å’Œæ ¼å¼ä½¿æŠ¥å‘Šæ˜“äºé˜…è¯»ã€‚å¦‚æœæä¾›çš„ä¿¡æ¯åŒ…å«å¸¦æœ‰ URL å’Œæè¿°çš„å›¾ç‰‡ï¼Œè¯·é€‰æ‹©æœ€ç›¸å…³çš„å›¾ç‰‡ï¼Œå¹¶ä½¿ç”¨æ ‡å‡† Markdown å›¾ç‰‡è¯­æ³• `![æè¿°](URL)` å°†å…¶åµŒå…¥æŠ¥å‘Šä¸­ã€‚å°†å›¾ç‰‡æ”¾ç½®åœ¨ç›¸å…³æ–‡æœ¬éƒ¨åˆ†é™„è¿‘ã€‚"
	if globalContext != "" {
		systemPrompt += "\n\næ¥è‡ªç”¨æˆ·çš„é‡è¦ä¸Šä¸‹æ–‡/æŒ‡ä»¤ï¼š\n" + globalContext
	}

	messages := []openai.ChatCompletionMessage{
		{
			Role:    openai.ChatMessageRoleSystem,
			Content: systemPrompt,
		},
		{
			Role:    openai.ChatMessageRoleUser,
			Content: prompt,
		},
	}

	req := openai.ChatCompletionRequest{
		Model:       r.model,
		Messages:    messages,
		Temperature: 0.5,
	}

	resp, err := r.client.CreateChatCompletion(ctx, req)
	if err != nil {
		return Result{
			TaskType: TaskTypeReport,
			Success:  false,
			Error:    err.Error(),
		}, err
	}

	report := resp.Choices[0].Message.Content

	if r.verbose {
		fmt.Printf("  âœ“ æŠ¥å‘Šå·²ç”Ÿæˆ (%d å­—èŠ‚)\n", len(report))
	}
	if r.interactionHandler != nil {
		r.interactionHandler.Log(fmt.Sprintf("âœ“ æŠ¥å‘Šå·²ç”Ÿæˆ (%d å­—èŠ‚)", len(report)))
	}

	return Result{
		TaskType: TaskTypeReport,
		Success:  true,
		Output:   report,
	}, nil
}

// RenderSubagent renders markdown to terminal-friendly format.
type RenderSubagent struct {
	verbose            bool
	renderHTML         bool
	interactionHandler InteractionHandler
}

// NewRenderSubagent creates a new RenderSubagent.
func NewRenderSubagent(verbose bool, renderHTML bool, interactionHandler InteractionHandler) *RenderSubagent {
	return &RenderSubagent{
		verbose:            verbose,
		renderHTML:         renderHTML,
		interactionHandler: interactionHandler,
	}
}

// Type returns the task type this subagent handles.
func (r *RenderSubagent) Type() TaskType {
	return TaskTypeRender
}

// Execute renders markdown content.
func (r *RenderSubagent) Execute(ctx context.Context, task Task) (Result, error) {
	if r.verbose {
		fmt.Println("ğŸ¨ æ¸²æŸ“ Subagent")
	}
	if r.interactionHandler != nil {
		r.interactionHandler.Log(fmt.Sprintf("> æ¸²æŸ“ Subagent: %s", task.Description))
	}

	// Get content from parameters or description
	content, ok := task.Parameters["content"].(string)
	if !ok {
		// Try to get from context (passed from previous task)
		if ctxContent, ok := task.Parameters["context"].([]string); ok && len(ctxContent) > 0 {
			// Try to find the output from the REPORT task
			var foundReport bool
			for i := len(ctxContent) - 1; i >= 0; i-- {
				if strings.Contains(ctxContent[i], "Output from REPORT task:") {
					content = ctxContent[i]
					// Extract the content after the header
					if idx := strings.Index(content, "\n"); idx != -1 {
						content = content[idx+1:]
					}
					foundReport = true
					break
				}
			}

			if !foundReport {
				// If no REPORT output found, use the last task's output
				content = ctxContent[len(ctxContent)-1]
				// Extract the content after the header if present
				if idx := strings.Index(content, "Output from "); idx != -1 {
					if newlineIdx := strings.Index(content[idx:], "\n"); newlineIdx != -1 {
						content = content[idx+newlineIdx+1:]
					}
				}
			}
			content = strings.TrimSpace(content)
		} else {
			content = task.Description
		}
	}

	if r.verbose {
		fmt.Printf("  æ­£åœ¨æ¸²æŸ“ %d å­—èŠ‚çš„å†…å®¹\n", len(content))
	}
	if r.interactionHandler != nil {
		r.interactionHandler.Log(fmt.Sprintf("æ­£åœ¨æ¸²æŸ“ %d å­—èŠ‚çš„å†…å®¹", len(content)))
	}

	// Render markdown
	var output string
	if r.renderHTML {
		extensions := parser.CommonExtensions | parser.AutoHeadingIDs
		p := parser.NewWithExtensions(extensions)
		doc := p.Parse([]byte(content))

		htmlFlags := html.CommonFlags | html.HrefTargetBlank | html.CompletePage
		opts := html.RendererOptions{Flags: htmlFlags, Title: "Agent Report"}
		renderer := html.NewRenderer(opts)

		output = string(gomarkdown.Render(doc, renderer))
	} else {
		output = string(markdown.Render(content, 80, 6))
	}

	return Result{
		TaskType: TaskTypeRender,
		Success:  true,
		Output:   output,
	}, nil
}
